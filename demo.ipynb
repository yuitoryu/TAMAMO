{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08117da2-217d-4f31-a8c8-ef10b7bf36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import math\n",
    "import importlib.util\n",
    "import random\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b243636-bc97-461b-b110-215381c84810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some modules\n",
    "# Get the current working directory\n",
    "current_working_directory = os.getcwd()\n",
    "sys.path.append(current_working_directory+'/tools/')\n",
    "sys.path.append(current_working_directory+'/model/')\n",
    "from ChartRatingBinder import extract, bind_rate\n",
    "from ChartHandler import chartDecomposer, bpmTotimeConverter, noteTokenizer\n",
    "from ChartStats import chartStats\n",
    "from TAMAMo import TokenAlignedMaimaiAnalyzerModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd135f4-c3a2-4220-8a55-a4b4c4b4676a",
   "metadata": {},
   "source": [
    "### This section is to tokenize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "79b0884c-4f45-4403-8b7c-86167886552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up payhs for files\n",
    "folder_path = r'../maimai2/'\n",
    "rating_file = r'乐谱.csv'\n",
    "save_dir_balanced = r'one_file_demo/token[13,15]_balanced.json'\n",
    "save_dir_sub = r'one_file_demo/token[13.8,14.2].json'\n",
    "info1 = [{'bound':[13,13.9], 'ratio':1}, {'bound':[14,15], 'ratio':2.5}]\n",
    "info2 = [{'bound':[13.8,13.9], 'ratio':1}, {'bound':[14,14.2], 'ratio':1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e0221f69-839d-4e7f-bf65-24677340783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_data(data, info, padding_up_to, shuffle=True, display_info=False):\n",
    "    # info[i]: [lower,upper]:typle/list, ratio:float/int\n",
    "    temp = []\n",
    "    output = []\n",
    "    for i in range(len(info)):\n",
    "        temp.append([])\n",
    "        for song in data:\n",
    "            if song['rating_num'] >= info[i]['bound'][0] and song['rating_num'] <= info[i]['bound'][1]:\n",
    "                converter = bpmTotimeConverter(data[i])\n",
    "                tokenizer = noteTokenizer(song)\n",
    "                temp[-1].append(tokenizer.output(padding_up_to=padding_up_to))\n",
    "\n",
    "        if display_info:\n",
    "            print(f'Number of songs with in [{info[i]['bound'][0]}, {info[i]['bound'][1]}] is {len(temp[-1])}')\n",
    "        whole_part = math.floor(info[i]['ratio'])\n",
    "        partial = math.floor((info[i]['ratio'] - whole_part) * len(temp[-1]))\n",
    "        output += temp[-1] * whole_part\n",
    "        output += temp[-1][:partial]\n",
    "        if display_info:\n",
    "            print(f'Number of songs added within [{info[i]['bound'][0]}, {info[i]['bound'][1]}] is {len(temp[-1])*whole_part+partial}')\n",
    "    random.shuffle(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "033f0f62-edd0-4572-98d0-ee284934dae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start extracting and binding rating with charts and primarily decompose the charts...\n",
      "Extracting, binding and decomposing are done.\n",
      "Start further handling the charts...\n",
      "Number of songs with in [13, 13.9] is 595\n",
      "Number of songs added within [13, 13.9] is 595\n",
      "Number of songs with in [14, 15] is 209\n",
      "Number of songs added within [14, 15] is 522\n",
      "Number of songs with in [13.8, 13.9] is 130\n",
      "Number of songs added within [13.8, 13.9] is 130\n",
      "Number of songs with in [14, 14.2] is 83\n",
      "Number of songs added within [14, 14.2] is 83\n",
      "Tokenization success\n",
      "Start saving token files...\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "rating = bind_rate(rating_file)\n",
    "dataset = extract(folder_path, rating)\n",
    "processed_data = []\n",
    "balanced_data = []\n",
    "sub_data = []\n",
    "print('Start extracting and binding rating with charts and primarily decompose the charts...')\n",
    "for song in dataset:\n",
    "    for diff in song['difficulty']:\n",
    "        fullchart = song['difficulty'][diff]\n",
    "        current = chartDecomposer()\n",
    "        current.decompose(fullchart, song['name'])\n",
    "        this_song_info = current.output_data()\n",
    "        processed_data.append(this_song_info)\n",
    "print('Extracting, binding and decomposing are done.')        \n",
    "\n",
    "print('Start further handling the charts...')         \n",
    "balanced_data = mix_data(processed_data, info1, 2200, display_info=True)\n",
    "sub_data = mix_data(processed_data, info2, 2200, display_info=True)\n",
    "print('Tokenization success')\n",
    "\n",
    "print('Start saving token files...')\n",
    "with open(save_dir_balanced, 'w') as fp:\n",
    "    json.dump(balanced_data, fp)\n",
    "fp.close()\n",
    "with open(save_dir_sub, 'w') as fp:\n",
    "    json.dump(sub_data, fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c81836-f0ac-43ff-a4bd-9272a30907fd",
   "metadata": {},
   "source": [
    "### This section is the first part of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bc819896-73cf-493b-bb40-88e983f0ca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading dataset...\n",
      "Dataset loaded. 1117 samples in total.\n",
      "Start training process...\n",
      "=======================================================================================\n",
      "Epoch [1/72], Train_loss: 0.6883, Valid_loss: 0.6814, Learning Rate: 0.001 at 2024-12-03 17:36:37.964317\n",
      "=======================================================================================\n",
      "Epoch [2/72], Train_loss: 0.6733, Valid_loss: 0.6618, Learning Rate: 0.001 at 2024-12-03 17:36:56.331850\n",
      "=======================================================================================\n",
      "Epoch [3/72], Train_loss: 0.6476, Valid_loss: 0.6056, Learning Rate: 0.001 at 2024-12-03 17:37:14.440605\n",
      "=======================================================================================\n",
      "Epoch [4/72], Train_loss: 0.5760, Valid_loss: 0.5519, Learning Rate: 0.001 at 2024-12-03 17:37:31.917190\n",
      "=======================================================================================\n",
      "Epoch [5/72], Train_loss: 0.5091, Valid_loss: 0.4987, Learning Rate: 0.001 at 2024-12-03 17:37:49.876275\n",
      "=======================================================================================\n",
      "Epoch [6/72], Train_loss: 0.4782, Valid_loss: 0.4426, Learning Rate: 0.001 at 2024-12-03 17:38:10.760964\n",
      "=======================================================================================\n",
      "Epoch [7/72], Train_loss: 0.4637, Valid_loss: 0.4302, Learning Rate: 0.001 at 2024-12-03 17:38:30.353655\n",
      "=======================================================================================\n",
      "Epoch [8/72], Train_loss: 0.4595, Valid_loss: 0.4465, Learning Rate: 0.001 at 2024-12-03 17:38:50.765001\n",
      "=======================================================================================\n",
      "Epoch [9/72], Train_loss: 0.4666, Valid_loss: 0.4611, Learning Rate: 0.001 at 2024-12-03 17:39:09.749931\n",
      "=======================================================================================\n",
      "Epoch [10/72], Train_loss: 0.4842, Valid_loss: 0.4301, Learning Rate: 0.001 at 2024-12-03 17:39:28.935706\n",
      "=======================================================================================\n",
      "Epoch [11/72], Train_loss: 0.4623, Valid_loss: 0.4232, Learning Rate: 0.001 at 2024-12-03 17:39:48.070105\n",
      "=======================================================================================\n",
      "Epoch [12/72], Train_loss: 0.4620, Valid_loss: 0.4295, Learning Rate: 0.001 at 2024-12-03 17:40:07.737450\n",
      "=======================================================================================\n",
      "Epoch [13/72], Train_loss: 0.4503, Valid_loss: 0.4209, Learning Rate: 0.001 at 2024-12-03 17:40:27.968410\n",
      "=======================================================================================\n",
      "Epoch [14/72], Train_loss: 0.4518, Valid_loss: 0.4356, Learning Rate: 0.001 at 2024-12-03 17:40:47.894178\n",
      "=======================================================================================\n",
      "Epoch [15/72], Train_loss: 0.4549, Valid_loss: 0.4177, Learning Rate: 0.001 at 2024-12-03 17:41:07.580617\n",
      "=======================================================================================\n",
      "Epoch [16/72], Train_loss: 0.4495, Valid_loss: 0.4298, Learning Rate: 0.001 at 2024-12-03 17:41:27.351335\n",
      "=======================================================================================\n",
      "Epoch [17/72], Train_loss: 0.4475, Valid_loss: 0.4204, Learning Rate: 0.001 at 2024-12-03 17:41:47.469522\n",
      "=======================================================================================\n",
      "Epoch [18/72], Train_loss: 0.4489, Valid_loss: 0.4182, Learning Rate: 0.001 at 2024-12-03 17:42:07.107948\n",
      "=======================================================================================\n",
      "Epoch [19/72], Train_loss: 0.4495, Valid_loss: 0.4296, Learning Rate: 0.001 at 2024-12-03 17:42:26.422666\n",
      "=======================================================================================\n",
      "Epoch [20/72], Train_loss: 0.4461, Valid_loss: 0.4227, Learning Rate: 0.001 at 2024-12-03 17:42:45.310891\n",
      "=======================================================================================\n",
      "Epoch [21/72], Train_loss: 0.4489, Valid_loss: 0.4248, Learning Rate: 0.001 at 2024-12-03 17:43:04.757819\n",
      "=======================================================================================\n",
      "Epoch [22/72], Train_loss: 0.4422, Valid_loss: 0.4331, Learning Rate: 0.001 at 2024-12-03 17:43:24.682628\n",
      "=======================================================================================\n",
      "Epoch [23/72], Train_loss: 0.4456, Valid_loss: 0.4127, Learning Rate: 0.0001 at 2024-12-03 17:43:44.799012\n",
      "=======================================================================================\n",
      "Epoch [24/72], Train_loss: 0.4387, Valid_loss: 0.4113, Learning Rate: 0.0001 at 2024-12-03 17:44:04.131869\n",
      "=======================================================================================\n",
      "Epoch [25/72], Train_loss: 0.4366, Valid_loss: 0.4114, Learning Rate: 0.0001 at 2024-12-03 17:44:22.999385\n",
      "=======================================================================================\n",
      "Epoch [26/72], Train_loss: 0.4351, Valid_loss: 0.4116, Learning Rate: 0.0001 at 2024-12-03 17:44:42.707104\n",
      "=======================================================================================\n",
      "Epoch [27/72], Train_loss: 0.4361, Valid_loss: 0.4126, Learning Rate: 0.0001 at 2024-12-03 17:45:01.706567\n",
      "=======================================================================================\n",
      "Epoch [28/72], Train_loss: 0.4347, Valid_loss: 0.4107, Learning Rate: 0.0001 at 2024-12-03 17:45:21.698196\n",
      "=======================================================================================\n",
      "Epoch [29/72], Train_loss: 0.4365, Valid_loss: 0.4111, Learning Rate: 0.0001 at 2024-12-03 17:45:40.907041\n",
      "=======================================================================================\n",
      "Epoch [30/72], Train_loss: 0.4346, Valid_loss: 0.4108, Learning Rate: 0.0001 at 2024-12-03 17:45:59.553893\n",
      "=======================================================================================\n",
      "Epoch [31/72], Train_loss: 0.4347, Valid_loss: 0.4110, Learning Rate: 0.0001 at 2024-12-03 17:46:18.774717\n",
      "=======================================================================================\n",
      "Epoch [32/72], Train_loss: 0.4341, Valid_loss: 0.4109, Learning Rate: 0.0001 at 2024-12-03 17:46:38.715957\n",
      "=======================================================================================\n",
      "Epoch [33/72], Train_loss: 0.4349, Valid_loss: 0.4103, Learning Rate: 0.0001 at 2024-12-03 17:46:57.608829\n",
      "=======================================================================================\n",
      "Epoch [34/72], Train_loss: 0.4340, Valid_loss: 0.4104, Learning Rate: 0.0001 at 2024-12-03 17:47:16.448661\n",
      "=======================================================================================\n",
      "Epoch [35/72], Train_loss: 0.4362, Valid_loss: 0.4146, Learning Rate: 0.0001 at 2024-12-03 17:47:35.861213\n",
      "=======================================================================================\n",
      "Epoch [36/72], Train_loss: 0.4332, Valid_loss: 0.4099, Learning Rate: 0.0001 at 2024-12-03 17:47:54.473405\n",
      "=======================================================================================\n",
      "Epoch [37/72], Train_loss: 0.4342, Valid_loss: 0.4115, Learning Rate: 0.0001 at 2024-12-03 17:48:13.016686\n",
      "=======================================================================================\n",
      "Epoch [38/72], Train_loss: 0.4335, Valid_loss: 0.4120, Learning Rate: 0.0001 at 2024-12-03 17:48:31.612686\n",
      "=======================================================================================\n",
      "Epoch [39/72], Train_loss: 0.4337, Valid_loss: 0.4106, Learning Rate: 0.0001 at 2024-12-03 17:48:50.946421\n",
      "=======================================================================================\n",
      "Epoch [40/72], Train_loss: 0.4335, Valid_loss: 0.4105, Learning Rate: 0.0001 at 2024-12-03 17:49:10.072958\n",
      "=======================================================================================\n",
      "Epoch [41/72], Train_loss: 0.4339, Valid_loss: 0.4111, Learning Rate: 0.0001 at 2024-12-03 17:49:28.587130\n",
      "=======================================================================================\n",
      "Epoch [42/72], Train_loss: 0.4339, Valid_loss: 0.4107, Learning Rate: 0.0001 at 2024-12-03 17:49:47.395949\n",
      "=======================================================================================\n",
      "Epoch [43/72], Train_loss: 0.4325, Valid_loss: 0.4110, Learning Rate: 0.0001 at 2024-12-03 17:50:06.212503\n",
      "=======================================================================================\n",
      "Epoch [44/72], Train_loss: 0.4329, Valid_loss: 0.4137, Learning Rate: 0.0001 at 2024-12-03 17:50:25.188784\n",
      "=======================================================================================\n",
      "Epoch [45/72], Train_loss: 0.4329, Valid_loss: 0.4099, Learning Rate: 0.0001 at 2024-12-03 17:50:43.907192\n",
      "=======================================================================================\n",
      "Epoch [46/72], Train_loss: 0.4333, Valid_loss: 0.4098, Learning Rate: 0.0001 at 2024-12-03 17:51:02.738822\n",
      "=======================================================================================\n",
      "Epoch [47/72], Train_loss: 0.4338, Valid_loss: 0.4094, Learning Rate: 0.0001 at 2024-12-03 17:51:21.576739\n",
      "=======================================================================================\n",
      "Epoch [48/72], Train_loss: 0.4325, Valid_loss: 0.4103, Learning Rate: 0.0001 at 2024-12-03 17:51:40.967455\n",
      "=======================================================================================\n",
      "Epoch [49/72], Train_loss: 0.4328, Valid_loss: 0.4113, Learning Rate: 0.0001 at 2024-12-03 17:51:59.852314\n",
      "=======================================================================================\n",
      "Epoch [50/72], Train_loss: 0.4330, Valid_loss: 0.4099, Learning Rate: 0.0001 at 2024-12-03 17:52:18.724664\n",
      "=======================================================================================\n",
      "Epoch [51/72], Train_loss: 0.4330, Valid_loss: 0.4120, Learning Rate: 0.0001 at 2024-12-03 17:52:37.585260\n",
      "=======================================================================================\n",
      "Epoch [52/72], Train_loss: 0.4313, Valid_loss: 0.4089, Learning Rate: 0.0001 at 2024-12-03 17:52:56.443220\n",
      "=======================================================================================\n",
      "Epoch [53/72], Train_loss: 0.4333, Valid_loss: 0.4093, Learning Rate: 0.0001 at 2024-12-03 17:53:15.178780\n",
      "=======================================================================================\n",
      "Epoch [54/72], Train_loss: 0.4324, Valid_loss: 0.4088, Learning Rate: 0.0001 at 2024-12-03 17:53:33.347407\n",
      "=======================================================================================\n",
      "Epoch [55/72], Train_loss: 0.4329, Valid_loss: 0.4110, Learning Rate: 0.0001 at 2024-12-03 17:53:51.833722\n",
      "=======================================================================================\n",
      "Epoch [56/72], Train_loss: 0.4317, Valid_loss: 0.4095, Learning Rate: 0.0001 at 2024-12-03 17:54:10.299152\n",
      "=======================================================================================\n",
      "Epoch [57/72], Train_loss: 0.4312, Valid_loss: 0.4110, Learning Rate: 0.0001 at 2024-12-03 17:54:28.832985\n",
      "=======================================================================================\n",
      "Epoch [58/72], Train_loss: 0.4322, Valid_loss: 0.4094, Learning Rate: 0.0001 at 2024-12-03 17:54:47.423082\n",
      "=======================================================================================\n",
      "Epoch [59/72], Train_loss: 0.4318, Valid_loss: 0.4117, Learning Rate: 0.0001 at 2024-12-03 17:55:05.969409\n",
      "=======================================================================================\n",
      "Epoch [60/72], Train_loss: 0.4319, Valid_loss: 0.4102, Learning Rate: 1e-05 at 2024-12-03 17:55:25.344047\n",
      "=======================================================================================\n",
      "Epoch [61/72], Train_loss: 0.4299, Valid_loss: 0.4095, Learning Rate: 1e-05 at 2024-12-03 17:55:43.908300\n",
      "=======================================================================================\n",
      "Epoch [62/72], Train_loss: 0.4304, Valid_loss: 0.4098, Learning Rate: 1e-05 at 2024-12-03 17:56:03.104402\n",
      "=======================================================================================\n",
      "Epoch [63/72], Train_loss: 0.4301, Valid_loss: 0.4096, Learning Rate: 1e-05 at 2024-12-03 17:56:21.663896\n",
      "=======================================================================================\n",
      "Epoch [64/72], Train_loss: 0.4302, Valid_loss: 0.4094, Learning Rate: 1e-05 at 2024-12-03 17:56:40.408598\n",
      "=======================================================================================\n",
      "Epoch [65/72], Train_loss: 0.4299, Valid_loss: 0.4096, Learning Rate: 1e-05 at 2024-12-03 17:56:59.067784\n",
      "=======================================================================================\n",
      "Epoch [66/72], Train_loss: 0.4300, Valid_loss: 0.4094, Learning Rate: 1e-05 at 2024-12-03 17:57:17.656769\n",
      "=======================================================================================\n",
      "Epoch [67/72], Train_loss: 0.4295, Valid_loss: 0.4094, Learning Rate: 1e-05 at 2024-12-03 17:57:36.293397\n",
      "=======================================================================================\n",
      "Epoch [68/72], Train_loss: 0.4304, Valid_loss: 0.4093, Learning Rate: 1e-05 at 2024-12-03 17:57:55.187007\n",
      "=======================================================================================\n",
      "Epoch [69/72], Train_loss: 0.4304, Valid_loss: 0.4093, Learning Rate: 1e-05 at 2024-12-03 17:58:14.083245\n",
      "=======================================================================================\n",
      "Epoch [70/72], Train_loss: 0.4296, Valid_loss: 0.4092, Learning Rate: 1e-05 at 2024-12-03 17:58:33.089144\n",
      "=======================================================================================\n",
      "Epoch [71/72], Train_loss: 0.4300, Valid_loss: 0.4094, Learning Rate: 1e-05 at 2024-12-03 17:58:52.105474\n",
      "=======================================================================================\n",
      "Epoch [72/72], Train_loss: 0.4306, Valid_loss: 0.4092, Learning Rate: 1e-05 at 2024-12-03 17:59:11.024003\n",
      "Best model comes from Epoch 67.\n",
      "Model training is done. Start saving checkpoint file...\n",
      "Checkpoint file saved.\n"
     ]
    }
   ],
   "source": [
    "# It will do training, so you need an Nvidia GPU or it will be super super slow.\n",
    "# I have no idea on how it works on Mac since I never use Macintosh system.\n",
    "# If you don't have access to an Nvidia GPU, please skip this part. A pretrained parameter file is already included.\n",
    "!python tools\\train.py --config configs\\model_class_bound[14]_data[13,15]_h3_l3_balance.py --device cuda --save_dir one_file_demo/first_train/final.pth --valid True --lossplot True --dataset one_file_demo\\token[13,15]_balanced.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279de798-7074-4fd2-8380-cba68c29f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image\n",
    "image = Image.open(r'one_file_demo\\first_train_loss.png')\n",
    "\n",
    "# Display the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ba9f1-fef9-488b-8afe-84bffc4cf0c6",
   "metadata": {},
   "source": [
    "### This section is the second part of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9deefe6b-4df4-47f4-96c9-9580422adca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading dataset...\n",
      "Dataset loaded. 213 samples in total.\n",
      "Start training process...\n",
      "=======================================================================================\n",
      "Epoch [1/72], Train_loss: 1.4360, Valid_loss: 1.5477, Learning Rate: 0.0001 at 2024-12-03 18:57:59.629124\n",
      "=======================================================================================\n",
      "Epoch [2/72], Train_loss: 1.4000, Valid_loss: 1.5059, Learning Rate: 0.0001 at 2024-12-03 18:58:03.256420\n",
      "=======================================================================================\n",
      "Epoch [3/72], Train_loss: 1.3636, Valid_loss: 1.4657, Learning Rate: 0.0001 at 2024-12-03 18:58:06.953336\n",
      "=======================================================================================\n",
      "Epoch [4/72], Train_loss: 1.3284, Valid_loss: 1.4228, Learning Rate: 0.0001 at 2024-12-03 18:58:10.647365\n",
      "=======================================================================================\n",
      "Epoch [5/72], Train_loss: 1.2880, Valid_loss: 1.3446, Learning Rate: 0.0001 at 2024-12-03 18:58:14.349222\n",
      "=======================================================================================\n",
      "Epoch [6/72], Train_loss: 1.2045, Valid_loss: 1.1833, Learning Rate: 0.0001 at 2024-12-03 18:58:18.082035\n",
      "=======================================================================================\n",
      "Epoch [7/72], Train_loss: 1.1252, Valid_loss: 1.1263, Learning Rate: 0.0001 at 2024-12-03 18:58:21.761068\n",
      "=======================================================================================\n",
      "Epoch [8/72], Train_loss: 1.0927, Valid_loss: 1.0983, Learning Rate: 0.0001 at 2024-12-03 18:58:25.407713\n",
      "=======================================================================================\n",
      "Epoch [9/72], Train_loss: 1.0726, Valid_loss: 1.0745, Learning Rate: 0.0001 at 2024-12-03 18:58:29.094908\n",
      "=======================================================================================\n",
      "Epoch [10/72], Train_loss: 1.0531, Valid_loss: 1.0572, Learning Rate: 0.0001 at 2024-12-03 18:58:32.710230\n",
      "=======================================================================================\n",
      "Epoch [11/72], Train_loss: 1.0318, Valid_loss: 1.0260, Learning Rate: 0.0001 at 2024-12-03 18:58:36.331392\n",
      "=======================================================================================\n",
      "Epoch [12/72], Train_loss: 1.0159, Valid_loss: 1.0012, Learning Rate: 0.0001 at 2024-12-03 18:58:39.962751\n",
      "=======================================================================================\n",
      "Epoch [13/72], Train_loss: 0.9925, Valid_loss: 0.9765, Learning Rate: 0.0001 at 2024-12-03 18:58:43.578172\n",
      "=======================================================================================\n",
      "Epoch [14/72], Train_loss: 0.9759, Valid_loss: 0.9606, Learning Rate: 0.0001 at 2024-12-03 18:58:47.195917\n",
      "=======================================================================================\n",
      "Epoch [15/72], Train_loss: 0.9491, Valid_loss: 0.9287, Learning Rate: 0.0001 at 2024-12-03 18:58:50.854203\n",
      "=======================================================================================\n",
      "Epoch [16/72], Train_loss: 0.9234, Valid_loss: 0.9114, Learning Rate: 0.0001 at 2024-12-03 18:58:54.522251\n",
      "=======================================================================================\n",
      "Epoch [17/72], Train_loss: 0.9061, Valid_loss: 0.8996, Learning Rate: 0.0001 at 2024-12-03 18:58:58.280540\n",
      "=======================================================================================\n",
      "Epoch [18/72], Train_loss: 0.9039, Valid_loss: 0.8901, Learning Rate: 0.0001 at 2024-12-03 18:59:01.950942\n",
      "=======================================================================================\n",
      "Epoch [19/72], Train_loss: 0.8845, Valid_loss: 0.8827, Learning Rate: 0.0001 at 2024-12-03 18:59:05.617942\n",
      "=======================================================================================\n",
      "Epoch [20/72], Train_loss: 0.8676, Valid_loss: 0.8706, Learning Rate: 0.0001 at 2024-12-03 18:59:09.286759\n",
      "=======================================================================================\n",
      "Epoch [21/72], Train_loss: 0.8630, Valid_loss: 0.8595, Learning Rate: 0.0001 at 2024-12-03 18:59:12.943082\n",
      "=======================================================================================\n",
      "Epoch [22/72], Train_loss: 0.8428, Valid_loss: 0.8472, Learning Rate: 0.0001 at 2024-12-03 18:59:16.578887\n",
      "=======================================================================================\n",
      "Epoch [23/72], Train_loss: 0.8376, Valid_loss: 0.8343, Learning Rate: 0.0001 at 2024-12-03 18:59:20.252373\n",
      "=======================================================================================\n",
      "Epoch [24/72], Train_loss: 0.8174, Valid_loss: 0.8240, Learning Rate: 0.0001 at 2024-12-03 18:59:24.023676\n",
      "=======================================================================================\n",
      "Epoch [25/72], Train_loss: 0.8051, Valid_loss: 0.8104, Learning Rate: 0.0001 at 2024-12-03 18:59:27.756620\n",
      "=======================================================================================\n",
      "Epoch [26/72], Train_loss: 0.8002, Valid_loss: 0.7969, Learning Rate: 0.0001 at 2024-12-03 18:59:31.458097\n",
      "=======================================================================================\n",
      "Epoch [27/72], Train_loss: 0.7892, Valid_loss: 0.7840, Learning Rate: 0.0001 at 2024-12-03 18:59:35.163368\n",
      "=======================================================================================\n",
      "Epoch [28/72], Train_loss: 0.7818, Valid_loss: 0.7723, Learning Rate: 0.0001 at 2024-12-03 18:59:38.883887\n",
      "=======================================================================================\n",
      "Epoch [29/72], Train_loss: 0.7645, Valid_loss: 0.7586, Learning Rate: 0.0001 at 2024-12-03 18:59:42.576859\n",
      "=======================================================================================\n",
      "Epoch [30/72], Train_loss: 0.7483, Valid_loss: 0.7445, Learning Rate: 0.0001 at 2024-12-03 18:59:46.212885\n",
      "=======================================================================================\n",
      "Epoch [31/72], Train_loss: 0.7366, Valid_loss: 0.7321, Learning Rate: 0.0001 at 2024-12-03 18:59:49.930684\n",
      "=======================================================================================\n",
      "Epoch [32/72], Train_loss: 0.7290, Valid_loss: 0.7197, Learning Rate: 0.0001 at 2024-12-03 18:59:53.599774\n",
      "=======================================================================================\n",
      "Epoch [33/72], Train_loss: 0.7142, Valid_loss: 0.7084, Learning Rate: 0.0001 at 2024-12-03 18:59:57.218086\n",
      "=======================================================================================\n",
      "Epoch [34/72], Train_loss: 0.7028, Valid_loss: 0.6973, Learning Rate: 0.0001 at 2024-12-03 19:00:00.838864\n",
      "=======================================================================================\n",
      "Epoch [35/72], Train_loss: 0.6915, Valid_loss: 0.6860, Learning Rate: 0.0001 at 2024-12-03 19:00:04.439294\n",
      "=======================================================================================\n",
      "Epoch [36/72], Train_loss: 0.6845, Valid_loss: 0.6761, Learning Rate: 0.0001 at 2024-12-03 19:00:08.015861\n",
      "=======================================================================================\n",
      "Epoch [37/72], Train_loss: 0.6725, Valid_loss: 0.6669, Learning Rate: 0.0001 at 2024-12-03 19:00:11.712129\n",
      "=======================================================================================\n",
      "Epoch [38/72], Train_loss: 0.6624, Valid_loss: 0.6580, Learning Rate: 0.0001 at 2024-12-03 19:00:15.324809\n",
      "=======================================================================================\n",
      "Epoch [39/72], Train_loss: 0.6578, Valid_loss: 0.6511, Learning Rate: 0.0001 at 2024-12-03 19:00:19.041575\n",
      "=======================================================================================\n",
      "Epoch [40/72], Train_loss: 0.6458, Valid_loss: 0.6442, Learning Rate: 0.0001 at 2024-12-03 19:00:22.655478\n",
      "=======================================================================================\n",
      "Epoch [41/72], Train_loss: 0.6518, Valid_loss: 0.6386, Learning Rate: 0.0001 at 2024-12-03 19:00:26.324260\n",
      "=======================================================================================\n",
      "Epoch [42/72], Train_loss: 0.6411, Valid_loss: 0.6357, Learning Rate: 0.0001 at 2024-12-03 19:00:29.925460\n",
      "=======================================================================================\n",
      "Epoch [43/72], Train_loss: 0.6375, Valid_loss: 0.6329, Learning Rate: 0.0001 at 2024-12-03 19:00:33.506316\n",
      "=======================================================================================\n",
      "Epoch [44/72], Train_loss: 0.6331, Valid_loss: 0.6296, Learning Rate: 0.0001 at 2024-12-03 19:00:37.133477\n",
      "=======================================================================================\n",
      "Epoch [45/72], Train_loss: 0.6301, Valid_loss: 0.6277, Learning Rate: 0.0001 at 2024-12-03 19:00:40.753234\n",
      "=======================================================================================\n",
      "Epoch [46/72], Train_loss: 0.6348, Valid_loss: 0.6270, Learning Rate: 0.0001 at 2024-12-03 19:00:44.401050\n",
      "=======================================================================================\n",
      "Epoch [47/72], Train_loss: 0.6340, Valid_loss: 0.6264, Learning Rate: 0.0001 at 2024-12-03 19:00:48.070912\n",
      "=======================================================================================\n",
      "Epoch [48/72], Train_loss: 0.6320, Valid_loss: 0.6253, Learning Rate: 0.0001 at 2024-12-03 19:00:51.665782\n",
      "=======================================================================================\n",
      "Epoch [49/72], Train_loss: 0.6266, Valid_loss: 0.6248, Learning Rate: 0.0001 at 2024-12-03 19:00:55.320359\n",
      "=======================================================================================\n",
      "Epoch [50/72], Train_loss: 0.6326, Valid_loss: 0.6246, Learning Rate: 1e-05 at 2024-12-03 19:00:59.001010\n",
      "=======================================================================================\n",
      "Epoch [51/72], Train_loss: 0.6261, Valid_loss: 0.6245, Learning Rate: 1e-05 at 2024-12-03 19:01:02.608421\n",
      "=======================================================================================\n",
      "Epoch [52/72], Train_loss: 0.6284, Valid_loss: 0.6245, Learning Rate: 1e-05 at 2024-12-03 19:01:06.171520\n",
      "=======================================================================================\n",
      "Epoch [53/72], Train_loss: 0.6302, Valid_loss: 0.6245, Learning Rate: 1e-05 at 2024-12-03 19:01:09.820694\n",
      "=======================================================================================\n",
      "Epoch [54/72], Train_loss: 0.6302, Valid_loss: 0.6245, Learning Rate: 1e-05 at 2024-12-03 19:01:13.547084\n",
      "=======================================================================================\n",
      "Epoch [55/72], Train_loss: 0.6279, Valid_loss: 0.6245, Learning Rate: 1e-05 at 2024-12-03 19:01:17.191897\n",
      "=======================================================================================\n",
      "Epoch [56/72], Train_loss: 0.6294, Valid_loss: 0.6245, Learning Rate: 1e-05 at 2024-12-03 19:01:20.884702\n",
      "=======================================================================================\n",
      "Epoch [57/72], Train_loss: 0.6301, Valid_loss: 0.6245, Learning Rate: 1e-05 at 2024-12-03 19:01:24.564211\n",
      "=======================================================================================\n",
      "Epoch [58/72], Train_loss: 0.6267, Valid_loss: 0.6245, Learning Rate: 1e-05 at 2024-12-03 19:01:28.246136\n",
      "=======================================================================================\n",
      "Epoch [59/72], Train_loss: 0.6305, Valid_loss: 0.6245, Learning Rate: 1e-05 at 2024-12-03 19:01:31.916244\n",
      "=======================================================================================\n",
      "Epoch [60/72], Train_loss: 0.6260, Valid_loss: 0.6245, Learning Rate: 1e-05 at 2024-12-03 19:01:35.620347\n",
      "=======================================================================================\n",
      "Epoch [61/72], Train_loss: 0.6236, Valid_loss: 0.6244, Learning Rate: 1e-05 at 2024-12-03 19:01:39.269944\n",
      "=======================================================================================\n",
      "Epoch [62/72], Train_loss: 0.6273, Valid_loss: 0.6243, Learning Rate: 1e-05 at 2024-12-03 19:01:42.991804\n",
      "=======================================================================================\n",
      "Epoch [63/72], Train_loss: 0.6295, Valid_loss: 0.6242, Learning Rate: 1e-05 at 2024-12-03 19:01:46.605870\n",
      "=======================================================================================\n",
      "Epoch [64/72], Train_loss: 0.6238, Valid_loss: 0.6241, Learning Rate: 1e-05 at 2024-12-03 19:01:50.216671\n",
      "=======================================================================================\n",
      "Epoch [65/72], Train_loss: 0.6248, Valid_loss: 0.6241, Learning Rate: 1e-05 at 2024-12-03 19:01:53.838983\n",
      "=======================================================================================\n",
      "Epoch [66/72], Train_loss: 0.6234, Valid_loss: 0.6241, Learning Rate: 1e-05 at 2024-12-03 19:01:57.457637\n",
      "=======================================================================================\n",
      "Epoch [67/72], Train_loss: 0.6251, Valid_loss: 0.6240, Learning Rate: 1e-05 at 2024-12-03 19:02:01.062560\n",
      "=======================================================================================\n",
      "Epoch [68/72], Train_loss: 0.6235, Valid_loss: 0.6239, Learning Rate: 1e-05 at 2024-12-03 19:02:04.744528\n",
      "=======================================================================================\n",
      "Epoch [69/72], Train_loss: 0.6212, Valid_loss: 0.6238, Learning Rate: 1e-05 at 2024-12-03 19:02:08.380539\n",
      "=======================================================================================\n",
      "Epoch [70/72], Train_loss: 0.6281, Valid_loss: 0.6238, Learning Rate: 1e-05 at 2024-12-03 19:02:11.992584\n",
      "=======================================================================================\n",
      "Epoch [71/72], Train_loss: 0.6279, Valid_loss: 0.6237, Learning Rate: 1e-05 at 2024-12-03 19:02:15.621465\n",
      "=======================================================================================\n",
      "Epoch [72/72], Train_loss: 0.6290, Valid_loss: 0.6237, Learning Rate: 1e-05 at 2024-12-03 19:02:19.313684\n",
      "Best model comes from Epoch 69.\n",
      "Model training is done. Start saving checkpoint file...\n",
      "Checkpoint file saved.\n"
     ]
    }
   ],
   "source": [
    "# This also does training.\n",
    "# Only execute it if you have an Nvidia GPU or you just want to waste your time.\n",
    "# Again, no idea if this works or not on Mac!!!!!!!!!!\n",
    "!python tools\\train.py --config configs/model_class_[13.8,14.2]_r[130,80]_from_bound[14]_data[13,15]_h3_l3_balance.py --device cuda --save_dir one_file_demo/second_train/final.pth --valid True --lossplot True --dataset one_file_demo\\token[13.8,14.2].json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c429a6c-6be5-4864-a543-10b6e7a25bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image\n",
    "image = Image.open(r'one_file_demo\\second_train_loss.png')\n",
    "\n",
    "# Display the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbcdb13-14e6-4568-b852-5122edb2b97c",
   "metadata": {},
   "source": [
    "### Evaluation Part\n",
    "Pretrained parameter file will be used in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a31ccc90-d577-441c-8fcb-34d916992fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading dataset...\n",
      "Dataset loaded. 213 samples in total.\n",
      "# of 13: 130\n",
      "# of 14: 83\n",
      "train_acc: 76.47%\n",
      "valid_acc: 75.12%\n",
      "acc: 75.12%\n",
      "f1: 78.88%\n",
      "positive_correct_rate: 76.15%\n",
      "neagtive_correct_rate: 73.49%\n",
      "true_positive: 99\n",
      "true_negative: 61\n",
      "false_positive: 22\n",
      "false_negative: 31\n",
      "Probability graph plotted and saved.\n"
     ]
    }
   ],
   "source": [
    "# It takes time when ytou use CPU.\n",
    "!python tools\\test.py --config configs/model_class_[13.8,14.2]_r[130,80]_from_bound[14]_data[13,15]_h3_l3_balance.py --device cuda --std tokens_[13.8,14.2]_r[130,83].json --checkpoint checkpoints\\model_class_[13.8,14.2]_r[130,83]_from_bound[14]_data[13,15]_h3_l3_balance_checkpoint.pth --dist \\data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fd20f01-ada3-4356-8e01-a934c69d3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image\n",
    "image = Image.open(r'data\\distribution.png')\n",
    "\n",
    "# Display the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f535694-e890-4c1e-b606-0918f8536be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
